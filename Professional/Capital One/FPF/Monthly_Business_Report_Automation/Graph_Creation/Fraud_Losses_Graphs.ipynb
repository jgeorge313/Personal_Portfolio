{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fraud Losses Graph\n",
    "\n",
    "The Fraud Losses Graph script pulls from tables built in **Fraud Losses** in order to create monthly views of Fraud Losses, split by various dimmensions that are important when understanding performance.\n",
    "\n",
    "\n",
    "Due to copyright reasons, the code has been largely modified and generalized so that code is vague and not revealing of corporate information. However, my hope is the audience an understand why the script is ordered in the way it is.\n",
    "\n",
    "## Script Outline\n",
    "\n",
    "The script is organized as follows:\n",
    "\n",
    "        1.Set-Up (imports, connections, creating variables)\n",
    "        2.Establishing Unit Test\n",
    "        3.SQL to extract data\n",
    "        4.Data formatting through Pandas\n",
    "        5.Slide Creation\n",
    "        6.Unit test execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Set-Up Explanation\n",
    "\n",
    "In order to successfully run this script there are a number of processes that must be done in order to connect to the data and run code. They are\n",
    "\n",
    "        Running the credentials file\n",
    "        Running utility scripts\n",
    "        Install the Capital One built package pptmaker\n",
    "        Importing packages\n",
    "        Creating useful variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:File `'Users/[EID]/creds.py'` not found.\n"
     ]
    }
   ],
   "source": [
    "#Step 1, run credentials files to connect to Capital One's Data infrastructure\n",
    "%run \"Users/[EID]/creds\"\n",
    "\n",
    "#If you are cloning this repository you will have to change the above to speciy your EID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2, run helpful utility scripts that predefine functions used throughout the script\n",
    "%run \"./Utilities/fraud_helper_fx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 3, install Capital One internally created package that can create a .pptx file of graphs/tables\n",
    "dbutils.library.installPyPi(\"pptmaker\", repo='....')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 4, import packages and create helpful variables\n",
    "\n",
    "from pptmaker import pptMaker\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import DataFrameStatFunctions as FS\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import re\n",
    "import json\n",
    "import pytz\n",
    "import os.path\n",
    "from pytz import timezone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up connection to snowflake so we can access productionized data\n",
    "snowflake_source_name = \"net.snowflake.spark.snowflake\"\n",
    "sfOptions = {\n",
    "    \"sfUrl\":\"...\",\n",
    "    \"sfUser\":username, #accessed from running creds file\n",
    "    \"sfPassword\":password,#accessed from running creds file\n",
    "    \"sfDatabase\":\"...\",\n",
    "    \"sfSchema\":\"USER_{}\".format(username),\n",
    "}\n",
    "\n",
    "Utils = spark.jvm.net.snowflake.spark.snowflake.Utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unit Test Explanation\n",
    "\n",
    "As mentioned throughout the repository, the \"unit test\" concept allows analysts to run just a single script and as an output receive just that script's outputted graphs. \n",
    "\n",
    "It's incredibly useful when debugging a singular script in the process of forming the entire MBR.\n",
    "\n",
    "To create the unit test parameter, we establish a widget in databricks with the command below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_test = dbutils.widgets.text(\"unit_test\", 'type Y for unit test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Extraction\n",
    "\n",
    "To get various graphs in the format that the team looks at them each month, I run the following SQL queries in databricks. The output of these are Spark data frames oriented in a wide manner. I convert the Spark Dataframe to a Pandas dataframe and then begin data formatting using Pandas.\n",
    "\n",
    "## Views of interest:\n",
    "\n",
    "        Losses by segment\n",
    "        Losses as a ratio to accounts, by segment compared against enterprise wide performance for the same metric\n",
    "        Losses by account age, by segment\n",
    "\n",
    "The actual script contains far more views than this, but has been simplified for educational purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Losses by segment Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SQL to pull losses from three core segments\n",
    "fraud_loss_chart_sql = \"\"\"select chargeoff_month, segment1_losses, segment2_losses, segment3_losses from lab_fpf.chart_loss\"\"\"\n",
    "\n",
    "#pull data from snowflake\n",
    "fraud_loss_spark_df = sf_load_query(fraud_loss_chart_sql)\n",
    "\n",
    "#convert to Pandas dataframe\n",
    "fraud_loss_pdf = fraud_loss_spark_df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reorient wide data into long data for grapphing purposes\n",
    "fraud_loss_chart = pd.melt(fraud_loss_pdf, id_vars = ['chargeoff_month'], var_name = 'segment', value_name = 'Fraud_Losses')\n",
    "\n",
    "#fix formatting of segment names to be consistently the first two letters of the segment:\n",
    "fraud_loss_chart['segment'] = fraud_loss_chart[segment].apply(lambda x:x x[:2])\n",
    "\n",
    "#format dates to be in the format Jan-21 for January 2021 rather than 2021-01-01\n",
    "fraud_loss_chart['chargeoff_month'].apply(lambda x:x.strftime('%b-%y'))\n",
    "\n",
    "#we now have fraud losses by month by segment ready to be graphed!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fraud accounts over total accounts, by segment and overall \n",
    "\n",
    "It's a very useful to understand the ratio of Fraud accounts relative to the total number of accounts. This way, we have an understanding for when Fraud is actually escalating. We can do this by segment, and re-aggregate to include the total Capital One portfolio ratio. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SQL to pull losses as a percentage of accounts, split by segment\n",
    "accts_query = '''select chargeoff_accts, all_accts, chargeoff_accts/NULLIF(all_accts,0) as fraud_rate, segment, chargeoff_month \n",
    "from\n",
    "lab_fpf.accts_losses_agg a\n",
    "left join lab_fpf.accts_portfolio_agg b on a.segment = b.segment\n",
    "and a.chargeoff_month = b.snap_date\n",
    "where segment in (segment1, segment2,segment3) order by 5;'''\n",
    "\n",
    "#SQL to pull losses as a percentage of accounts not split by segment, we want to compare how the segments chart against\n",
    "#the entire portfolio\n",
    "total_by_acct_query = '''select sum(chargeoff_accts) as chargeoff_accts, sum(all_accts) as all_accts,\n",
    "sum(chargeoff_accts)/sum(all_accts) as fraud_rate, chargeoff_month \n",
    "from \n",
    "lab_fpf.accts_losses agg a\n",
    "left join lab_fpf.accts_portfolio_agg b on a.segment = b.segment\n",
    "and a.chargeoff_month = b.snap_date\n",
    "group by 4 order by 4;''''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pull from snowflake, convert to pandas\n",
    "accts_spark_pdf = sf_load_query(accts_query).toPandas()\n",
    "total_accts_pdf = sf_load_query(total_by_acct_query).toPandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for the enterprise wide dataframe, create an segment column so the entire data can be shown with one graph\n",
    "\n",
    "total_accts_pdf['segment'] = 'Overall'\n",
    "\n",
    "#concatenate the dataframes\n",
    "accts_final_pdf = pd.concat([accts_pdf, total_accts_pdf])\n",
    "\n",
    "#format chargeoff month\n",
    "accts_final_pdf['Formatted_Chargeoff_Month'] = accts_final_pdf['chargeoff_month'].apply(lambda x:x.strftime('%b-%y'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Losses by segment and account age bin\n",
    "\n",
    "In our data creation scripts we created four tables:\n",
    "        \n",
    "        chart_loss_age_1: losses from accounts < 1 year old\n",
    "        chart_loss_age_2: losses fromaccounts between 1-2 years old\n",
    "        chart_loss_age_4: losses from accounts beteween 2-4 years old\n",
    "        chart_loss_age_9: losses from accounts accounts aged 4 years +\n",
    "        \n",
    "To get these views, we run simple queries on these various tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SQL to pull losses by age bin and segment\n",
    "loss_age_1_query =  \"\"\"select chargeoff_month, segment1_losses, segment2_losses, segment3_losses from lab_fpf.chart_loss_age1\"\"\"\n",
    "loss_age_2_query =  \"\"\"select chargeoff_month, segment1_losses, segment2_losses, segment3_losses from lab_fpf.chart_loss_age2\"\"\"\n",
    "loss_age_4_query =  \"\"\"select chargeoff_month, segment1_losses, segment2_losses, segment3_losses from lab_fpf.chart_loss_age4\"\"\"\n",
    "loss_age_9_query =  \"\"\"select chargeoff_month, segment1_losses, segment2_losses, segment3_losses from lab_fpf.chart_loss_age9\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pull data from snowflake, convert to pandas dataframe\n",
    "loss_age_1 = sf_load_query(loss_age_1_query).toPandas()\n",
    "loss_age_2 = sf_load_query(loss_age_2_query).toPandas()\n",
    "loss_age_4 = sf_load_query(loss_age_4_query).toPandas()\n",
    "loss_age_9 = sf_load_query(loss_age_9_query).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort data by charge_off month\n",
    "loss_age_1 = loss_age_1.sort_values(['chargeoff_month'])\n",
    "loss_age_2 = loss_age_2.sort_values(['chargeoff_month'])\n",
    "loss_age_4 = loss_age_4.sort_values(['chargeoff_month'])\n",
    "loss_age_9 = loss_age_9.sort_values(['chargeoff_month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#melt into long data\n",
    "loss_age_1 = pd.melt(loss_age_1, id_vars = ['chargeoff_month'], var_name = 'segment', value_name = 'Fraud_Losses') \n",
    "loss_age_2 = pd.melt(loss_age_2, id_vars = ['chargeoff_month'], var_name = 'segment', value_name = 'Fraud_Losses')\n",
    "loss_age_4 = pd.melt(loss_age_4, id_vars = ['chargeoff_month'], var_name = 'segment', value_name = 'Fraud_Losses')\n",
    "loss_age_9 = pd.melt(loss_age_9, id_vars = ['chargeoff_month'], var_name = 'segment', value_name = 'Fraud_Losses')\n",
    "\n",
    "#format segment name to first two letters\n",
    "\n",
    "loss_age_1['segment'] = loss_age_1['segment'].str[:2]\n",
    "loss_age_2['segment'] = loss_age_2['segment'].str[:2]\n",
    "loss_age_4['segment'] = loss_age_4['segment'].str[:2]\n",
    "loss_age_9['segment'] = loss_age_9['segment'].str[:2]\n",
    "\n",
    "#format date\n",
    "loss_age_1['chargeoff_month'] = loss_age_1['chargeoff_month'].apply(lambda x: x.strftime('%b-%y'))\n",
    "loss_age_2['chargeoff_month'] = loss_age_2['chargeoff_month'].apply(lambda x: x.strftime('%b-%y'))\n",
    "loss_age_4['chargeoff_month'] = loss_age_4['chargeoff_month'].apply(lambda x: x.strftime('%b-%y'))\n",
    "loss_age_9['chargeoff_month'] = loss_age_9['chargeoff_month'].apply(lambda x: x.strftime('%b-%y'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slide Creation\n",
    "\n",
    "From here, we take the formatted pandas dataframes and run them through the pptMaker functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a powerpoint object that will generate slides in the following commands\n",
    "ppt = pptMaker.pptMaker()\n",
    "\n",
    "#specify the x axis order of string dates \n",
    "date_format_list = fraud_loss_chart['Formatted_Chargeoff_Month'].unique().tolist()\n",
    "date_format_list.sort(key = lambda date: datetime.strptime(date, '%b-%y'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following code has output is attached in the repositoy \n",
    "\n",
    "The image of the losses by segments 1 -3 corresponds to the output of the following command in the \"FPF\" folder of the repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#slide 1 losses by segment\n",
    "\n",
    "Losses_by_seg_graph = ppt.createChart(fraud_loss_chart #pandas dataframe input\n",
    "                               ,metric = 'Fraud_Losses' #y value for graphs\n",
    "                               ,x_axis = 'Formatted_Chargeoff_Month' #x-axis\n",
    "                               ,splitter = 'segment' #different colors\n",
    "                               ,chart_type = 'Column_Stacked' #graph type\n",
    "                               ,x_sort = date_format_list #order of x axis\n",
    "                               ,chart_name = 'Fraud Losses'\n",
    "                               ,chart_sub_name = 'By Segment by Charge-off Month'\n",
    "                               ,number_format = '\"\\$#,,.0 M\"' #y axis unit formatting\n",
    "                               ,x_label = 'Chargeoff Month'\n",
    "                                      \n",
    "#the create_month_over_month_precents_fraud_losses function can be found in the utility folder in the MBR_FX script\n",
    "#the input is the dataframe with the metric of interest, and the name of the metric to calculate the month-over-month \n",
    "#percent difference                               )\n",
    "Losses_by_seg_table = ppt.createTable(create_month_over_month_percents_fraud_losses(fraud_loss_chart, 'Fraud_Losses'))\n",
    "\n",
    "##ppt.createSlide takes in a list of charts, a list of tables, the slide header, and any footnote text\n",
    "slide1 = ppt.createSlide(charts = [Losses_by_seg_graph] \n",
    "                        , tables = [Losses_by_seg_table]\n",
    "                        , slide_name = 'Looking at Fraud Losses split by segment'\n",
    "                        ,notes = 'Person of Contact: Joby George' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#slide 2 losses as a ratio of accounts, split by segment\n",
    "Fraud_ratio_graph = ppt.createChart(accts_final_pdf #pandas dataframe input\n",
    "                               ,metric = 'fraud_rate' #y value for graphs\n",
    "                               ,x_axis = 'Formatted_Chargeoff_Month' #x-axis\n",
    "                               ,splitter = 'segment' #different colors\n",
    "                               ,chart_type = 'Line' #graph type\n",
    "                               ,x_sort = date_format_list #order of x axis\n",
    "                               ,chart_name = 'Number of Fraud accounts in comparison to overall bookings'\n",
    "                               ,chart_sub_name = 'By Segment by Chargeoff Month'\n",
    "                               ,number_format = 'percent' #y axis unit formatting\n",
    "                               ,x_label = 'Chargeoff Month'\n",
    "                               )\n",
    "#the create_month_over_month_precents_fraud_losses function can be found in the utility folder in the MBR_FX script\n",
    "#the input is the dataframe with the metric of interest, and the name of the metric to calculate the month-over-month \n",
    "#percent difference\n",
    "Fraud_ratio_table= ppt.createTable(create_month_over_month_percents_fraud_losses(accts_final_pdf, 'fraud_rate'))\n",
    "\n",
    "##ppt.createSlide takes in a list of charts, a list of tables, the slide header, and any footnote text\n",
    "slide2 = = ppt.createSlide(charts = [Fraud_ratio_graph]\n",
    "                        , tables = [Fraud_ratio_table]\n",
    "                        , slide_name = 'Looking at Fraud Ratio split by segment'\n",
    "                        ,notes = 'Person of Contact: Joby George' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#four charts for losses by acct age:\n",
    "\n",
    "young_fraud_losses = ppt.createChart(loss_age_1 #pandas dataframe input\n",
    "                               ,metric = 'fraud_losses' #y value for graphs\n",
    "                               ,x_axis = 'Formatted_Chargeoff_Month' #x-axis\n",
    "                               ,splitter = 'segment' #different colors\n",
    "                               ,chart_type = 'Line' #graph type\n",
    "                               ,x_sort = date_format_list #order of x axis\n",
    "                               ,chart_name = 'Fraud Losses for accounts under one year old'\n",
    "                               ,chart_sub_name = 'By Segment by Chargeoff Month'\n",
    "                               ,number_format = '\"\\$#,,.0 M\"' #y axis unit formatting\n",
    "                               ,x_label = 'Chargeoff Month'\n",
    "                               )\n",
    "\n",
    "one_year_fraud_losses = ppt.createChart(loss_age_2 #pandas dataframe input\n",
    "                               ,metric = 'fraud_losses' #y value for graphs\n",
    "                               ,x_axis = 'Formatted_Chargeoff_Month' #x-axis\n",
    "                               ,splitter = 'segment' #different colors\n",
    "                               ,chart_type = 'Line' #graph type\n",
    "                               ,x_sort = date_format_list #order of x axis\n",
    "                               ,chart_name = 'Fraud Losses for accounts between 1-2 years old'\n",
    "                               ,chart_sub_name = 'By Segment by Chargeoff Month'\n",
    "                               ,number_format = '\"\\$#,,.0 M\"' #y axis unit formatting\n",
    "                               ,x_label = 'Chargeoff Month'\n",
    "                               )\n",
    "\n",
    "middle_age_fraud_losses = ppt.createChart(loss_age_4 #pandas dataframe input\n",
    "                               ,metric = 'fraud_losses' #y value for graphs\n",
    "                               ,x_axis = 'Formatted_Chargeoff_Month' #x-axis\n",
    "                               ,splitter = 'segment' #different colors\n",
    "                               ,chart_type = 'Line' #graph type\n",
    "                               ,x_sort = date_format_list #order of x axis\n",
    "                               ,chart_name = 'Fraud Losses for accounts between 2-4 years old'\n",
    "                               ,chart_sub_name = 'By Segment by Chargeoff Month'\n",
    "                               ,number_format = '\"\\$#,,.0 M\"' #y axis unit formatting\n",
    "                               ,x_label = 'Chargeoff Month'\n",
    "                               )\n",
    "\n",
    "elder_fraud_losses = ppt.createChart(loss_age_9 #pandas dataframe input\n",
    "                               ,metric = 'fraud_losses' #y value for graphs\n",
    "                               ,x_axis = 'Formatted_Chargeoff_Month' #x-axis\n",
    "                               ,splitter = 'segment' #different colors\n",
    "                               ,chart_type = 'Line' #graph type\n",
    "                               ,x_sort = date_format_list #order of x axis\n",
    "                               ,chart_name = 'Fraud Losses for accounts older than 4 years old'\n",
    "                               ,chart_sub_name = 'By Segment by Chargeoff Month'\n",
    "                               ,number_format = '\"\\$#,,.0 M\"' #y axis unit formatting\n",
    "                               ,x_label = 'Chargeoff Month'\n",
    "                               )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a slide containing these four graphs\n",
    "slide3 = ppt.createSlide(charts = [young_fraud_losses, one_year_fraud_losses, middle_age_fraud_losses, elder_fraud_losses],\n",
    "                        , slide_name = 'Looking at Fraud losses by age bin, split by segment'\n",
    "                        ,notes = 'Person of Contact: Joby George' )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unit Test Execution\n",
    "\n",
    "To run this script as a stand-alone component from the trigger script, I wrote a simple if statement that looks for the value of the variable unit_test, which was pass as a parameter in the trigger script\n",
    "\n",
    "If the unit test is in one of the accepted values, the deck is sent out to recipients, if it is not, the slides remain a part of the ppt object, until they are finally sent out in the last command of the trigger script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if unit_test in unit_test_acpt_values:\n",
    "    ppt.createDeck(ppt_name = 'FPF_Losses_MBR ' + str(datetime.now(timezone(\"America/New_York\")).strftime('%Y_%m_%d_%H')),\n",
    "    email_to = recipients,\n",
    "    email_from = dev_email,\n",
    "    email_subject = 'FPF_Losses_MBR ' + str(datetime.now(timezone(\"America/New_York\")).strftime('%Y_%m_%d_%H')),\n",
    "    ppt_attach = True)\n",
    "else:\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
