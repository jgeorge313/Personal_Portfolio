{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defense Performance Data Creation \n",
    "\n",
    "The Defense Performance Data Creation script is a series of SQL queries that is executed. These queries are run each Friday at 5 in the morning via a databricks scheduled job so analysts can come to work with the data already ready to be reported on.\n",
    "\n",
    "It is very similar to the Fraud Losses Data Creation Script in structure, but differs in the data location\n",
    "\n",
    "Due to copyright reasons, the code has been largely modified and simplified so that code is vague and not revealing of corporate information. However, my hope is the logic and planned structure of the Capital One's First Party Fraud Monthly Business Report Repository is communicated.\n",
    "\n",
    "\n",
    "## Script Outline\n",
    "\n",
    "The script is organized as follows:\n",
    "\n",
    "        1.Set-Up (imports, connections, creating variables)\n",
    "        2.Writing SQL queries\n",
    "        3.Running SQL queries\n",
    "        4.Granting privledge to newly created tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Set-Up Explanation\n",
    "\n",
    "In order to successfully run this script there are a number of processes that must be done in order to connect to the data and run code. They are\n",
    "\n",
    "        Running the credentials file\n",
    "        Running utility scripts\n",
    "        Install the Capital One built package pptmaker\n",
    "        Importing packages\n",
    "        Creating useful variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:File `'Users/[EID]/creds.py'` not found.\n"
     ]
    }
   ],
   "source": [
    "#Step 1, run credentials files to connect to Capital One's Data infrastructure\n",
    "%run \"Users/[EID]/creds\"\n",
    "\n",
    "#If you are cloning this repository you will have to change the above to speciy your EID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2, run helpful utility scripts that predefine functions used throughout the script\n",
    "%run \"./Utilities/fraud_helper_fx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"./Utilities/MBR_fx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 3, install Capital One internally created package that can create a .pptx file of graphs/tables\n",
    "dbutils.library.installPyPi(\"pptmaker\", repo='....')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 4, import packages and create helpful variables\n",
    "\n",
    "from pptmaker import pptMaker\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import DataFrameStatFunctions as FS\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import re\n",
    "import json\n",
    "import pytz\n",
    "import os.path\n",
    "from pytz import timezone\n",
    "\n",
    "#name developers and recipients -- change this if you are cloning the repository\n",
    "\n",
    "dev_email = ['joby.george@capitalone.com']\n",
    "recipients = ['joby.george@capitalone.com']\n",
    "\n",
    "#set timezone to EST \n",
    "tz = pytz.timezone('America/New_York')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up connection to snowflake so we can access productionized data\n",
    "snowflake_source_name = \"net.snowflake.spark.snowflake\"\n",
    "sfOptions = {\n",
    "    \"sfUrl\":\"...\",\n",
    "    \"sfUser\":username, #accessed from running creds file\n",
    "    \"sfPassword\":password,#accessed from running creds file\n",
    "    \"sfDatabase\":\"...\",\n",
    "    \"sfSchema\":\"USER_{}\".format(username),\n",
    "}\n",
    "\n",
    "Utils = spark.jvm.net.snowflake.spark.snowflake.Utils\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing SQL Queries\n",
    "\n",
    "### Note all code is highly simplified to avoid disclosing confidential information\n",
    "\n",
    "Our goal is to have granular and aggregated data tables containing all instances of our defense firing and the number of cases that are indeed fraudulent. \n",
    "\n",
    "To do this, we create a table with the case firings of defenses in First Party Fraud \n",
    "\n",
    "After that we simply aggregate the number of cases by case outcome (fraud/not Fraud) and by month\n",
    "\n",
    "We lastly need to look at hit rate  in an aggregated fashion\n",
    "With data that can be aggregated, we build tables that mimic the monthly reporting of the monthly business report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a table of the First Party Fraud defenses\n",
    "defense_table = '''\n",
    "create or replace table lab_fpf.defense_base as (\n",
    "    select\n",
    "        case_id\n",
    "        ,acct_id\n",
    "        ,fraud_defense_id\n",
    "        ,case when frd_dfns_id in (1,2) then 'FPF Model'\n",
    "        when frd_dfns_id in (3,4,5,6,7) then 'risky email'\n",
    "        when frd_dfns_id in (8) then 'risky SSN'\n",
    "        when frd_dfns_id in (9,20,11,45,21,15) then 'malicious young account'\n",
    "        when frd dfns id in (100, 101,105,215,213,107,143,214,341,78,213,765) then 'agent defenses'\n",
    "        else frd_dfns_id\n",
    "        end as defense\n",
    "        , fraud_case_resolution_code\n",
    "        , cast(fraud_case_creation_timestamp as DATE) as case_date\n",
    "        ,date_trunc('month', case_date) as case_month\n",
    "        , case when fraud_case_resolution_code = '-1' then 'Pending',\n",
    "        when fraud_case_resolution_code = '10' then 'Fraud'\n",
    "        when fraud_case_resolution_code = '0' then 'not Fraud'\n",
    "        end as case_outcome\n",
    "        , case when case_outcome = 'Fraud' then 1 else 0 end as fraud_ind\n",
    "    from defense_table \n",
    "    where defense in ('FPF Model', 'risky email', risky SSN', 'malicious young account', 'agent defenses')\n",
    "    and case_date between dateadd(month, -24, date_trunc(month, current_date)) and dateadd(day, -1, date_trunc(month, current_date))\n",
    "        );'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at aggregated volume, \n",
    "agg_defenses = '''create or replace table lab_fpf.case_size as (\n",
    "    select \n",
    "        case_month\n",
    "        ,defense\n",
    "        ,count(distinct(case_id)) as case_size\n",
    "        )\n",
    "    from lab_fpf.defense_base\n",
    "    group by 1,2\n",
    "    order by 1,2);'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at aggregated hit rate\n",
    "hit_rate_base = '''\n",
    "create or replace table lab_fpf.df_hitrate_graph_base as (\n",
    "    select \n",
    "        case_month\n",
    "        ,defense\n",
    "        ,count(distinct(acct_id)) as fraud_count\n",
    "        ,count(distinct(case_id)) as fraud_case_size\n",
    ")\n",
    "    from lab_fpf.defense_base\n",
    "    where fraud_ind = 1\n",
    "    group by 1,2\n",
    "    order by 1,2);'''\n",
    "\n",
    "hit_rate_agg = '''\n",
    "create or replace table lab_fpf.df_hitrate_graph as (\n",
    "    select \n",
    "        a.case_month\n",
    "        ,a.defense\n",
    "        ,a.fraud_count\n",
    "        ,b.case_size\n",
    "        ,a.fraud_count/b.case_size as hit_rate\n",
    ")\n",
    "    from lab_fpf.df_hitrate_graph_base a\n",
    "    left join lab_fpf.case_size b\n",
    "    on a.case_month = b.case_month\n",
    "    and a.defense = b.defense\n",
    "   );'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the queries\n",
    "\n",
    "In order to have databricks run the text queries above we use the \n",
    "Utils.runQuery(query) syntax for all of the above queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run date tab\n",
    "query_list = [defense_table\n",
    "             ,agg_defenses\n",
    "             ,hit_rate_base\n",
    "             ,hit_rate_agg\n",
    "\n",
    "             ]\n",
    "for query in query_list:\n",
    "    Utils.runQuery(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grant Privledges to the tables\n",
    "\n",
    "Similarly we just need to Utils.runQuery(''grant select on table to all_users''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_list = ['lab_fpf.defense_base'\n",
    "              ,'lab_fpf.case_size'\n",
    "              ,'lab_fpf.df_hitrate_graph_base'\n",
    "              ,'lab_fpf.df_hitrate_graph'\n",
    "             ]\n",
    "\n",
    "for table in table_list:\n",
    "    Utils.runQuery('grant select on ' + table + ' to all_users')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
