{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fraud Losses Data Creation\n",
    "\n",
    "The Fraud Losses Data Creation script is a series of SQL queries that is executed. These queries are run each Friday at 5 in the morning via a databricks scheduled job so analysts can come to work with the data already ready to be reported on.\n",
    "\n",
    "\n",
    "Due to copyright reasons, the code has been largely modified and simplified so that code is vague and not revealing of corporate information. However, my hope is the logic and planned structure of the Capital One's First Party Fraud Monthly Business Report Repository is communicated.\n",
    "\n",
    "\n",
    "## Script Outline\n",
    "\n",
    "The script is organized as follows:\n",
    "\n",
    "        1.Set-Up (imports, connections, creating variables)\n",
    "        2.Writing SQL queries\n",
    "        3.Running SQL queries\n",
    "        4.Granting privledge to newly created tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Set-Up Explanation\n",
    "\n",
    "In order to successfully run this script there are a number of processes that must be done in order to connect to the data and run code. They are\n",
    "\n",
    "        Running the credentials file\n",
    "        Running utility scripts\n",
    "        Install the Capital One built package pptmaker\n",
    "        Importing packages\n",
    "        Creating useful variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:File `'Users/[EID]/creds.py'` not found.\n"
     ]
    }
   ],
   "source": [
    "#Step 1, run credentials files to connect to Capital One's Data infrastructure\n",
    "%run \"Users/[EID]/creds\"\n",
    "\n",
    "#If you are cloning this repository you will have to change the above to speciy your EID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2, run helpful utility scripts that predefine functions used throughout the script\n",
    "%run \"./Utilities/fraud_helper_fx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"./Utilities/MBR_fx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 3, install Capital One internally created package that can create a .pptx file of graphs/tables\n",
    "dbutils.library.installPyPi(\"pptmaker\", repo='....')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 4, import packages and create helpful variables\n",
    "\n",
    "from pptmaker import pptMaker\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import DataFrameStatFunctions as FS\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import re\n",
    "import json\n",
    "import pytz\n",
    "import os.path\n",
    "from pytz import timezone\n",
    "\n",
    "#name developers and recipients -- change this if you are cloning the repository\n",
    "\n",
    "dev_email = ['joby.george@capitalone.com']\n",
    "recipients = ['joby.george@capitalone.com']\n",
    "\n",
    "#set timezone to EST \n",
    "tz = pytz.timezone('America/New_York')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up connection to snowflake so we can access productionized data\n",
    "snowflake_source_name = \"net.snowflake.spark.snowflake\"\n",
    "sfOptions = {\n",
    "    \"sfUrl\":\"...\",\n",
    "    \"sfUser\":username, #accessed from running creds file\n",
    "    \"sfPassword\":password,#accessed from running creds file\n",
    "    \"sfDatabase\":\"...\",\n",
    "    \"sfSchema\":\"USER_{}\".format(username),\n",
    "}\n",
    "\n",
    "Utils = spark.jvm.net.snowflake.spark.snowflake.Utils\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing SQL Queries\n",
    "\n",
    "### Note all code is highly simplified to avoid disclosing confidential information\n",
    "\n",
    "Our goal is to have granular and aggregated data tables containing losses (both fraud and credit losses), where we can easily categorize which losses and accounts are first party fraud. \n",
    "\n",
    "To do this, we create a table with the months of data that we'll pull from.\n",
    "\n",
    "After that we pull from the losses table to see all accounts that have charged-off.\n",
    "\n",
    "From there we classify these accounts into segments and age buckets.\n",
    "\n",
    "With data that can be aggregated, we build tables that mimic the monthly reporting of the monthly business report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a table of dates that we will reference\n",
    "# we want the tables to include everything in the past two years until the 1st of the current month\n",
    "date_tab = '''\n",
    "create or replace table lab_fpf.date_tab as (\n",
    "    select\n",
    "        date_trunc('month', dateadd(month, -1, current_date)) as max_date\n",
    "        ,date_trunc('month', dateadd(month, -24, current_date)) as min_date\n",
    "    );'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#losses on an account level\n",
    "losses_table = '''\n",
    "create or replace table lab_fpf.losses_base as (\n",
    "    select\n",
    "        acct_id\n",
    "        ,balance as losses\n",
    "        ,credit_limit\n",
    "        ,chrgof_dt as chargeoff_date\n",
    "        ,date_trunc('month', chrgof_dt) as chargeoff_month\n",
    "        ,open_dt\n",
    "        ,datediff(day, open_dt, chrgof_dt) as age\n",
    "        ,fraud_indicator\n",
    "    from\n",
    "    chrgof_table\n",
    "    where snap_dt between (select min_date from lab_fpf.date_tab) and (select max_date from lab_fpf.date_tab)\n",
    "    );'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classifiying the account into segments\n",
    "losses_base_segment = '''\n",
    "create or replace table lab_fpf.loses_segment as (\n",
    "    select a.*,\n",
    "           , b.segment \n",
    "           , case when age < 365 then 1\n",
    "           when age between 365 and 730 then 2\n",
    "           when age between 731 and 1460 then 4\n",
    "           when age >= 1461 then 9\n",
    "           end as acct_age_bin\n",
    "   from lab_fpf.losses_base a\n",
    "   left join lab_fpf.segments b\n",
    "   on a.acct_id = b.acct_id \n",
    ");'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aggregate the data\n",
    "losses_agg = '''\n",
    "create or replace talbe lab_fpf.losses_agg as (\n",
    "    select\n",
    "        chargeoff_month\n",
    "        ,segment\n",
    "        ,fraud_indicator\n",
    "        ,acct_age_bin\n",
    "        ,sum(losses) as total_losses\n",
    "        , count(*) as num_chargeoffs\n",
    "    from lab_fpf.losses_segment\n",
    "    group by 1,2,3,4\n",
    "    order by 1,2,3,4);'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create specific aggregated segment loss table\n",
    "#this table is used in the fraud losses graph script\n",
    "segment_losses_agg = '''\n",
    "create or repalce table lab_fpf.chart_fraud_loss as (\n",
    "    select\n",
    "        chargeoff_month\n",
    "        ,sum(case when segment = 1 then total_losses else 0 end) as segment_1_losses)\n",
    "        ,sum(case when segment = 2 then total_losses else 0 end) as segment_2_losses)\n",
    "        ,sum(case when segment = 3 then total_losses else 0 end) as segment_3_losses)\n",
    "    from lab_fpf.losses_agg\n",
    "    where fraud_indicator = 1\n",
    "    group by 1\n",
    "    order by 1\n",
    "        );\n",
    "        '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a table for fraud losses for each age bin, split by segment\n",
    "young_losses_agg = '''\n",
    "create or repalce table lab_fpf.chart_fraud_loss_age1 as (\n",
    "    select\n",
    "        chargeoff_month\n",
    "        ,sum(case when segment = 1 then total_losses else 0 end) as segment_1_losses_1)\n",
    "        ,sum(case when segment = 2 then total_losses else 0 end) as segment_2_losses_1)\n",
    "        ,sum(case when segment = 3 then total_losses else 0 end) as segment_3_losses_1)\n",
    "    from lab_fpf.losses_agg\n",
    "    where fraud_indicator = 1\n",
    "    and acct_age_bin = 1\n",
    "    group by 1\n",
    "    order by 1\n",
    "        );'''\n",
    "        \n",
    "#repeat for accounts aged between 1-2 years\n",
    "two_year_losses_agg = '''\n",
    "create or repalce table lab_fpf.chart_fraud_loss_age2 as (\n",
    "    select\n",
    "        chargeoff_month\n",
    "        ,sum(case when segment = 1 then total_losses else 0 end) as segment_1_losses_2)\n",
    "        ,sum(case when segment = 2 then total_losses else 0 end) as segment_2_losses_2)\n",
    "        ,sum(case when segment = 3 then total_losses else 0 end) as segment_3_losses_2)\n",
    "    from lab_fpf.losses_agg\n",
    "    where fraud_indicator = 1\n",
    "    and acct_age_bin = 2\n",
    "    group by 1\n",
    "    order by 1\n",
    "        );'''\n",
    "\n",
    "#repeat for accounts aged between 2-4\n",
    "middle_age_losses_agg = '''\n",
    "create or repalce table lab_fpf.chart_fraud_loss_age4 as (\n",
    "    select\n",
    "        chargeoff_month\n",
    "        ,sum(case when segment = 1 then total_losses else 0 end) as segment_1_losses_4)\n",
    "        ,sum(case when segment = 2 then total_losses else 0 end) as segment_2_losses_4)\n",
    "        ,sum(case when segment = 3 then total_losses else 0 end) as segment_3_losses_4)\n",
    "    from lab_fpf.losses_agg\n",
    "    where fraud_indicator = 1\n",
    "    and acct_age_bin = 4\n",
    "    group by 1\n",
    "    order by 1\n",
    "        );'''\n",
    "\n",
    "#repeat for accounts aged more than 4 years\n",
    "elder_losses_agg = '''\n",
    "create or repalce table lab_fpf.chart_fraud_loss_age9 as (\n",
    "    select\n",
    "        chargeoff_month\n",
    "        ,sum(case when segment = 1 then total_losses else 0 end) as segment_1_losses_9)\n",
    "        ,sum(case when segment = 2 then total_losses else 0 end) as segment_2_losses_9)\n",
    "        ,sum(case when segment = 3 then total_losses else 0 end) as segment_3_losses_9)\n",
    "    from lab_fpf.losses_agg\n",
    "    where fraud_indicator = 1\n",
    "    and acct_age_bin = 9\n",
    "    group by 1\n",
    "    order by 1\n",
    "        );'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the queries\n",
    "\n",
    "In order to have databricks run the text queries above we use the \n",
    "Utils.runQuery(query) syntax for all of the above queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run date tab\n",
    "query_list = [date_tab\n",
    "             ,losses_table\n",
    "             ,losses_base_segment\n",
    "             ,losses_agg\n",
    "             ,segment_losses_agg\n",
    "             ,young_losses_agg\n",
    "             ,two_year_losses_agg\n",
    "             ,middle_age_losses_agg\n",
    "             ,elder_losses_agg\n",
    "             ]\n",
    "for query in query_list:\n",
    "    Utils.runQuery(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grant Privledges to the tables\n",
    "\n",
    "Similarly we just need to Utils.runQuery(''grant select on table to all_users''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_list = ['lab_fpf.date_tab'\n",
    "              ,'lab_fpf.losses_table'\n",
    "              ,'lab_fpf.losses_base'\n",
    "              ,'lab_fpf.losses_agg\n",
    "              ,'lab_fpf.chart_fraud_loss\n",
    "              ,'lab_fpf.chart_fraud_loss_age1'\n",
    "              ,'lab_fpf.chart_fraud_loss_age2'\n",
    "              ,'lab_fpf.chart_fraud_loss_age4'\n",
    "              ,'lab_fpf.chart_fraud_loss_age9'\n",
    "             ]\n",
    "\n",
    "for table in table_list:\n",
    "    Utils.runQuery('grant select on ' + table + ' to all_users')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
